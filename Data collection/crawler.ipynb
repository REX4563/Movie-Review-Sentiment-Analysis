{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import requests\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting all the movie titles and links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 8/8 [00:54<00:00,  6.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loading the current path\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "with tqdm(total=8, desc = \"processing\", leave = True) as pbar:\n",
    "    for iter in range(1,9):\n",
    "        # Accessing the HTML text.\n",
    "        imdb_link = f\"https://www.imdb.com/list/ls000634294/?st_dt=&mode=detail&page={iter}&sort=list_order,asc\"\n",
    "\n",
    "        url = requests.get(imdb_link).text\n",
    "        soup = BeautifulSoup(url, \"html.parser\")\n",
    "\n",
    "        # Find the specific div element\n",
    "        list_detail_div = soup.find(\"div\", class_=\"lister-list\")\n",
    "\n",
    "        # Find all lister-item mode-detail elements\n",
    "        movie_items = list_detail_div.find_all(\"div\", class_=\"lister-item mode-detail\")\n",
    "\n",
    "        # Find the next page\n",
    "        next_page = soup.find('a', class_ = 'flat-button lister-page-next next-page')\n",
    "\n",
    "        # Fuction to extract movie titles and links\n",
    "        def extract_TL():\n",
    "            # Initialize empty lists to store titles and links\n",
    "            titles = []\n",
    "            links = []\n",
    "\n",
    "            for item in movie_items:\n",
    "                # Find the <a> tag containing the movie title\n",
    "                title_tag = item.find(\"a\", href=True)\n",
    "                if title_tag:\n",
    "                    # Extract the title from the alt attribute of the img tag\n",
    "                    title = title_tag.find('img')['alt']\n",
    "                    titles.append(title)\n",
    "\n",
    "                    # Find the href of the title\n",
    "                    href = title_tag['href']\n",
    "\n",
    "                    # Check if the href starts with \"/title/tt\"\n",
    "                    if href.startswith('/title/tt'):\n",
    "                        # Combine the IMDb link\n",
    "                        full_link = f\"https://www.imdb.com{href}reviews?ref_=ttls_li_tt\"\n",
    "\n",
    "                        # Append the full link to the list\n",
    "                        links.append(full_link)\n",
    "            return titles, links\n",
    "\n",
    "        titles, links = extract_TL()\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame({'Movie Title': titles, 'IMDb Link': links})\n",
    "        df.to_excel(fr'{current_dir}\\movielinks\\file{iter}.xlsx', index=False)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all the 'movie titles and links' as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles = []\n",
    "Links = []\n",
    "\n",
    "# Iterating through all the files containg movie titles and links\n",
    "\n",
    "for count in range(1, 9):\n",
    "    path = fr'{current_dir}\\movielinks\\file{count}.xlsx'\n",
    "    try:\n",
    "        file = openpyxl.load_workbook(path)\n",
    "        for sheet in file:\n",
    "            # Append the entire column to Titles\n",
    "            Titles_column = [cell.value for cell in sheet['A'][1:]]\n",
    "            Titles.append(Titles_column)\n",
    "            \n",
    "            # Append the entire column to Links\n",
    "            Links_column = [cell.value for cell in sheet['B'][1:]]\n",
    "            Links.append(Links_column)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the 'reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 787/787 [23:52<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Function to sanitize the title string for use as a file name\n",
    "\n",
    "def sanitize_title(title_str):\n",
    "    valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
    "    sanitized_title = ''.join(c for c in title_str if c in valid_chars)\n",
    "    return sanitized_title\n",
    "\n",
    "directory = fr\"{current_dir}\\movielinks\\review links\"\n",
    "\n",
    "# Flatten the Links list\n",
    "flattened_links = [link for sublist in Links for link in sublist]\n",
    "\n",
    "with tqdm(total=len(flattened_links), desc=\"processing\") as pbar2:\n",
    "    for link in flattened_links:\n",
    "        title_str = str()\n",
    "        review_links = []\n",
    "\n",
    "        headers = {'User-Agent': 'MyIMDbScraper/1.0 (https://github.com/yourusername/my-imdb-scraper)'}\n",
    "        page = requests.get(link, headers=headers).text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "        lister = soup.find('div', class_='lister-list')\n",
    "        lister_items = lister.find_all('div', class_='lister-item-content')\n",
    "        sub_page = soup.find('div', class_='subpage_title_block')\n",
    "\n",
    "        # Extract movie title\n",
    "        title_tag = sub_page.find(\"h3\", itemprop=\"name\")\n",
    "        if title_tag:\n",
    "            # Extract the text content of the <a> tag inside the <h3> tag\n",
    "            title_str = title_tag.find('a').text\n",
    "            # Sanitize the title string for use as a file name\n",
    "            title_str = sanitize_title(title_str)\n",
    "\n",
    "        for item in lister_items:\n",
    "            a = item.find('a', class_='title')\n",
    "            if a:\n",
    "                href = a['href']\n",
    "                review_links.append(f'https://www.imdb.com{href}')\n",
    "        rdf = pd.DataFrame(review_links)\n",
    "\n",
    "        rdf.to_excel(fr'{directory}\\{title_str}.xlsx')\n",
    "        pbar2.update(1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
